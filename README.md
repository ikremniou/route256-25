# Track

## Task 1
- [x] с помощью команды `make run-all` можно запустить приложение (используется docker compose)
- [x] приложение слушает HTTP запросы на порту 8080 (а product service находиться внутри docker network)
- [x] реализовано POST /user/<user_id>/cart/<sku_id>
- [x] реализовано DELETE /user/<user_id>/cart/<sku_id>
- [x] реализовано DELETE /user/<user_id>/cart
- [x] реализовано GET /user/<user_id>/cart
- [x] методы реализуют заявленную бизнес логику
- [x] методы валидируют запросы и отдают описанные в спецификации коды ошибок (так как спецификации на ответ по добавлению в корзину нет, то я решил сделать code 201 когда товар добавился и 200 когда товар уже есть - тесты в пайплайне ожидают только 200, тут недочёт в пайплайнах)
- [x] информация о пользователях и их состоянии корзины хранится в памяти приложения
- [x] при рестарте приложения состояние системы теряется

***
- [x] Middleware, который будет логировать поступающие запросы
- [x] Валидацию входящих структур на основе любой open-source библиотеки (https://github.com/go-playground/validator)
- [x] Ретраи в `products` на 420/429 статус в виде Client Middleware. 3 ретрая, потом ошибка(я просто возвращаю реквест со статусом обратно, не создавая новую ошибку так как это, как мне кажется, более корректно)

Также мне очень не нравится момент когда мы делаем loop в GET /user/<user_id>/cart в микросервис products. Второй endpoint микросервиса никак не помогает решить проблему.

## Task 2
- [x] Написаны Unit-тесты слоя UseCase для каждого запроса
- [x] Написаны Unit-тесты слоя Repository сервиса Cart
- [x] Процент покрытия** тестируемых слоев **должен быть не менее 60%
- [x] Использовать библиотеку minimock для создания моков (Библиотека minimock — https://github.com/gojuno/minimock)
- [x] В make создать команду для расчета coverage. **Тут я создал комманду для расчёта общего coverage**

***
- [x] Написать два позитивных e2e теста для хендлера cart/item/delete и cart/list
- [x] Настроить линтер для проверки цикломатической и когнитивной сложности (https://github.com/fzipp/gocyclo и https://github.com/uudashr/gocognit)
- [x] Написать бенчмарк для InMemory Storage сервиса Cart (хотя бы одну операцию — добавление/удаление и т.д.)

## Task 3
- [x] Создать protobuf контракт сервиса loms
- [x] В каждом проекте нужно добавить в Makefile команды для генерации .go файлов из proto файлов и установки нужных зависимостей (используем protoc)
- [x] Состояние храним в in-memory, персистентное хранилище на данный момент не требуется. 2 репозитория - Stock и Order
- [x] Код должен быть покрыт юнит тестами
- [x] Добавить HTTP-gateway

***
- [x] Добавить swagger-ui и возможность совершать запросы из swagger к сервису
- [x] Написать end-to-end тесты на все новые методы - написал на hurl, нету времени :(
- [x] gRPC интерцептор. Валидация proto структур через proto-gen-validator


## Task 4
- [x] Для сервиса loms реализовать в слое Repository поход в БД
- [x] Развернуть экземпляр БД PostgreSQL в отдельном контейнере
- [x] В коде должен быть хотя бы один пример транзакции, состоящей из нескольких последовательных SQL запросов
- [x] Реализовать автоматические миграции, накатывающие схему БД и/или тестовые данные
- [x] SQL код должен быть написан в виде raw. Без использования ORM или билдеров (можно sqlc)

***
- [x] Для БД поднять синхронную реплику. Балансировать read/write запросы между ними (write только в master, read в любую из реплик)
- [x] Написать по одному интеграционному тесту на каждый SQL запрос в репозитории сервиса Loms. Не забыть накатывать тестовые данные в миграции, после прогона тестов - удалить данные из БД
- [x] Реализовать SQL-запросы с помощью sqlc


## Task 5
- [x]  Распараллелить вызовы ручки ProductService/ProductService_GetProduct продакт сервиса
- [x]  Самим написать аналог https://pkg.go.dev/golang.org/x/sync/errgroup и использовать его
- [x]  В случае ошибки– отменять все текущие запросы и вернуть ошибку из errgroup
- [x]  При общении с Product Service необходимо использовать лимит 10 RPS на клиентской стороне
- [x]  Группа живет в рамках одного запроса = группа не переиспользуется между запросами
- [x]  in-memory репозитории защитить мьютексами

***
- [x]  Написать тесты на многопоточность in-memory репозитория
- [x]  Поддержать обработку сигналов (использовать signal.Notify) и реализовать грейсфул завершение приложения
- [x]  Написать тесты на контроль утечек горутин (через https://github.com/uber-go/goleak)
- [x]  Написать тесты на контроль условий гонки (через тесты с флагом -race)
- [x]  Реализовать параллельный запуск тестов

## Task 6
- [x]  Добавить Apache Kafka и ее компоненты в docker окружение:
    - [x]  контейнер с брокером
    - [x]  контейнер с ui админкой на базе provectuslabs/kafka-ui
    - [x]  контейнер для инициализации окружения
- [x]  Настроить очередь для событий заказов при старте окружения:
    - [x]  название очереди должно быть `loms.order-events`
    - [x]  фактор репликации должен быть равен 1
    - [x]  у очереди должно быть 2 партиции
- [x]  Доработать сервис loms для отправки событий статуса заказа:
    - [x]  реализовать код конфигурации и подключения к Kafka
    - [x]  реализовать продюсер
    - [x]  обеспечить гарантированную запись в БД перед ответом пользователю
    - [x]  запрещать отправку событий при ошибке записи в БД
- [x]  Разработать новый сервис notifier:
    - [x]  добавить сервис в docker окружение
    - [x]  реализовать код конфигурации и подключения к Kafka
    - [x]  реализовать консьюмер для логирования событий о заказах
    - [x]  использовать consumer группу с хранением смещений в Kafka
    - [x]  фиксировать смещение после успешной обработки сообщения
    - [x]  обеспечить возобновление с необработанного сообщения при рестарте
    - [x]  реализовать обработку и логирование ошибок
- [x]  Обеспечить любой уровень гарантий доставки сообщений между loms и notifier
- [x]  Реализовать корректное завершение (gracefully shutdown) продюсера и консьюмера

***
- [x] на стороне loms (продюсера) необходимо реализовать tx outbox, создание/изменение заказа и запись в outbox должны происходить в одной транзакции с записью в специальную таблицу
- [x] необходимо реализовать фоновый процесс, который будет отправлять сообщения из outbox в Kafka, допускается использовать горутину с time.Ticker и опрашивать таблицу outbox с некоторым интервалом, задаваемым через конфигурацию. При наличии неотправленных событий, обрабатывать их
- [x] допускается при разборе outbox-а держать транзакцию открытой на момент отправки сообщения в очередь во избежание конкурентного доступа к outbox. Это ограничение допустимо в рамках учебного проекта, но на практике лучше избегать удержания открытых транзакций
- [x] допускается использовать синхронный продюсер


## Task 7
- [x]  Покрыть loms и cart метриками:
    - [x]  Возвращать метрики по API `/metrics`
    - [x]  Покрыть gRPC взаимодействие с переиспользованием функций
    - [x]  Отслеживать количество запросов (все ручки)
    - [x]  Отслеживать время и статус исполнения запросов – статус код, очищенный url
    - [x]  Отслеживать количество запросов во внешние ресурсы
    - [x]  Отслеживать время и статус запросов во внешние ресурсы
    - [x]  Отслеживать количество запросов в базу по категориям (select, update, delete)
    - [x]  Отслеживать время и статус запросов в базу с учетом ошибок и категорий
    - [x]  Возвращать метрикиazо API `/metrics`
    - [x]  Покрыть gRPC взаимодействие с переиспользованием функций
    - [x]  Отслеживать количество запросов (все ручки)
    - [x]  Отслеживать время и статус исполнения запросов – статус код, очищенный url
    - [x]  Отслеживать количество запросов во внешние ресурсы
    - [x]  Отслеживать время и статус запросов во внешние ресурсы
    - [x]  Отслеживать количество запросов в базу по категориям (select, update, delete)
    - [x]  Отслеживать время и статус запросов в базу с учетом ошибок и категорий
- [x]  Реализовать трейсинг во всей цепочке сервисов
- [x]  Перевести все логи на структурированный формат с корректными уровнями
- [x]  Создать make таргет для инфраструктуры мониторинга:
    - [x]  Настроить Prometheus с таргетами в Docker Compose
    - [x]  Настроить Grafana с Prometheus
    - [x]  Настроить Jaeger для сбора трейсинга
- [x]  Настроить трейсинг в Jaeger и сделать скриншот трейса для тьютора

***
- [ ]  Добавить в логи: имя сервиса, таймстемп, trace_id и span_id
- [x]  Добавить сбор профилей pprof по HTTP
- [x]  Добавить метрику количества объектов в in-memory репозитории cart


# Task 8
To Do